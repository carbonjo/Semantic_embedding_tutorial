{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Search Engine Demo\n",
        "\n",
        "This notebook demonstrates how to use semantic embeddings to perform semantic search. Semantic search understands the *meaning* of text, not just keyword matching.\n",
        "\n",
        "## What You'll Learn\n",
        "- How to use pre-trained embedding models\n",
        "- How to convert text into numerical vectors (embeddings)\n",
        "- How to find semantically similar documents using cosine similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Required Libraries\n",
        "\n",
        "First, we need to install the necessary libraries. Run this cell once to install the dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.11/site-packages (5.1.2)\n",
            "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (2.3.4)\n",
            "Requirement already satisfied: scikit-learn in ./venv/lib/python3.11/site-packages (1.7.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./venv/lib/python3.11/site-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n",
            "Requirement already satisfied: scipy in ./venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in ./venv/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in ./venv/lib/python3.11/site-packages (from sentence-transformers) (12.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in ./venv/lib/python3.11/site-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary library\n",
        "%pip install sentence-transformers numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries\n",
        "\n",
        "Import the required libraries for our semantic search implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/carbonjo/Library/CloudStorage/Dropbox/BSC-teaching+/Semesters/Fall25/DSA587-DSAwithG-AI/Materials/SemanticSearchEngine/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load the Embedding Model\n",
        "\n",
        "We'll use a pre-trained model from Hugging Face. The `all-MiniLM-L6-v2` model is a lightweight but effective model that converts text into 384-dimensional vectors.\n",
        "\n",
        "**Note:** The first time you run this, it will download the model (about 80MB). Subsequent runs will use the cached version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Load the Embedding Model ---\n",
        "# This loads the model from the Hugging Face Hub (sentence-transformers/all-MiniLM-L6-v2)\n",
        "print(\"Loading model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Define the Knowledge Base (Corpus)\n",
        "\n",
        "This is our collection of documents that we want to search through. In a real application, this could be thousands or millions of documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2. Define the Knowledge Base (Corpus) ---\n",
        "documents = [\n",
        "    \"The sky is a vivid shade of blue today.\",\n",
        "    \"The newest iPhone model was released with a powerful new chip.\",\n",
        "    \"A majestic hawk was spotted flying high above the forest canopy.\",\n",
        "    \"Apple is set to announce its latest mobile device with updated features.\",\n",
        "    \"I'm enjoying a picnic on the grass.\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Embeddings for the Corpus\n",
        "\n",
        "Convert each document in our corpus into a numerical vector (embedding). These embeddings capture the semantic meaning of the text.\n",
        "\n",
        "**Key Concept:** Similar meanings will have similar vectors, even if they use different words!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 5 embeddings, each with a dimension of 384.\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Create Embeddings for the Corpus ---\n",
        "# The .encode() function converts the text into numerical vectors (embeddings)\n",
        "document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "print(f\"Generated {len(document_embeddings)} embeddings, each with a dimension of {document_embeddings.shape[1]}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Define a Query and Create its Embedding\n",
        "\n",
        "Now we'll create a search query. Notice that our query doesn't use the exact same words as the documents, but it should still find the relevant document about phones!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4. Define a Query and Create its Embedding ---\n",
        "query = \"Tell me about the recent phone technology releases.\"\n",
        "query_embedding = model.encode([query], convert_to_tensor=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Perform Semantic Search (Calculate Similarity)\n",
        "\n",
        "We calculate the cosine similarity between the query embedding and all document embeddings.\n",
        "\n",
        "**Cosine Similarity:**\n",
        "- Ranges from -1 (opposite meaning) to 1 (identical meaning)\n",
        "- Values close to 1 indicate high semantic similarity\n",
        "- Values close to 0 indicate low similarity\n",
        "\n",
        "We'll find the document with the highest similarity score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5. Perform Semantic Search (Calculate Similarity) ---\n",
        "# We calculate the cosine similarity between the query embedding and ALL document embeddings.\n",
        "# Cosine similarity ranges from -1 (opposite meaning) to 1 (identical meaning).\n",
        "similarities = cosine_similarity(query_embedding.cpu().numpy(), document_embeddings.cpu().numpy())\n",
        "\n",
        "# Get the index of the most similar document\n",
        "most_similar_index = np.argmax(similarities)\n",
        "max_similarity_score = similarities[0, most_similar_index]\n",
        "best_match_document = documents[most_similar_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Display Results\n",
        "\n",
        "Let's see which document was found as the best match for our query!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Query: **Tell me about the recent phone technology releases.**\n",
            "==================================================\n",
            "Best Match (Score: 0.5846):\n",
            "'Apple is set to announce its latest mobile device with updated features.'\n"
          ]
        }
      ],
      "source": [
        "# --- 6. Print Results ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Query: **{query}**\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Best Match (Score: {max_similarity_score:.4f}):\")\n",
        "print(f\"'{best_match_document}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Explore All Similarity Scores (Optional)\n",
        "\n",
        "Let's see the similarity scores for all documents to better understand how the semantic search works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Similarity scores for all documents:\n",
            "--------------------------------------------------\n",
            "\n",
            "Document 1 (Score: 0.0485):\n",
            "  'The sky is a vivid shade of blue today.'\n",
            "\n",
            "Document 2 (Score: 0.5450):\n",
            "  'The newest iPhone model was released with a powerful new chip.'\n",
            "\n",
            "Document 3 (Score: -0.0547):\n",
            "  'A majestic hawk was spotted flying high above the forest canopy.'\n",
            "\n",
            "Document 4 (Score: 0.5846):\n",
            "  'Apple is set to announce its latest mobile device with updated features.'\n",
            "\n",
            "Document 5 (Score: -0.0379):\n",
            "  'I'm enjoying a picnic on the grass.'\n"
          ]
        }
      ],
      "source": [
        "# Display similarity scores for all documents\n",
        "print(\"\\nSimilarity scores for all documents:\")\n",
        "print(\"-\" * 50)\n",
        "for i, (doc, score) in enumerate(zip(documents, similarities[0])):\n",
        "    print(f\"\\nDocument {i+1} (Score: {score:.4f}):\")\n",
        "    print(f\"  '{doc}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try It Yourself!\n",
        "\n",
        "Experiment with different queries to see how semantic search works:\n",
        "\n",
        "- Try queries about nature, technology, or daily activities\n",
        "- Notice how the model finds relevant documents even when they don't share exact keywords\n",
        "- Compare the similarity scores to understand the ranking\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
